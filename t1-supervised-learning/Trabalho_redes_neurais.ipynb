{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5GN3EpDn4b"
      },
      "source": [
        "\n",
        "Imports e definição do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpxhsZya71hk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDIkF_VLuJUz"
      },
      "source": [
        "## Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B_QbKcy4FAY"
      },
      "outputs": [],
      "source": [
        "# Carregar conjunto de dados\n",
        "cifar10 = keras.datasets.cifar10\n",
        "(train_images_cifar10, train_labels_cifar10), (test_images_cifar10, test_labels_cifar10) = cifar10.load_data()\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels_cifar10 = tf.keras.utils.to_categorical(train_labels_cifar10, num_classes=num_classes)\n",
        "test_labels_cifar10 = tf.keras.utils.to_categorical(test_labels_cifar10, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPrIRBmT8XiN"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo de rede neural convolucional simples\n",
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(32, 32, 3)),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(256, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uN8v8_m8cvR",
        "outputId": "af58d656-f29e-4326-f9c7-020b8fec975b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 30, 30, 128)       4224      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 15, 15, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 15, 15, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 13, 13, 128)       147584    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 13, 13, 256)       33024     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 6, 6, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 4, 4, 256)         65792     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 2, 2, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 853386 (3.26 MB)\n",
            "Trainable params: 852618 (3.25 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 19s 10ms/step - loss: 1.3366 - accuracy: 0.5347\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.9687 - accuracy: 0.6674\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8524 - accuracy: 0.7103\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7912 - accuracy: 0.7343\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.7411 - accuracy: 0.7507\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.7139 - accuracy: 0.7615\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6865 - accuracy: 0.7757\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6439 - accuracy: 0.7878\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.6092 - accuracy: 0.7980\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.5778 - accuracy: 0.8099\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.8651 - accuracy: 0.7384\n",
            "Acurácia no conjunto de teste: 73.84%\n"
          ]
        }
      ],
      "source": [
        "# Treino e Teste\n",
        "model = get_cifar10_network()\n",
        "model.fit(train_images_cifar10, train_labels_cifar10, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images_cifar10, test_labels_cifar10)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5BH8DoZwQdA"
      },
      "source": [
        "## Cifar100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1abuXLN4pt8"
      },
      "outputs": [],
      "source": [
        "# Carregar conjunto de dados\n",
        "cifar100 = tf.keras.datasets.cifar100\n",
        "(train_images_cifar100, train_labels_cifar100), (test_images_cifar100, test_labels_cifar100) = cifar100.load_data()\n",
        "\n",
        "# Normaliza imagens\n",
        "train_images_cifar100 = train_images_cifar100.astype('float32')/255\n",
        "test_images_cifar100 = test_images_cifar100.astype('float32')/255\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels_cifar100 = tf.keras.utils.to_categorical(train_labels_cifar100)\n",
        "test_labels_cifar100 = tf.keras.utils.to_categorical(test_labels_cifar100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUkWfdxwwQA1"
      },
      "outputs": [],
      "source": [
        "def get_cifar100_network():\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(32, 32, 3)),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Conv2D(256, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(1024, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(1024, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(100, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='Adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctn1OITjwO1I",
        "outputId": "cb2a8f09-63bd-432c-d6a4-a6d66c77c4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 30, 30, 128)       4224      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 15, 15, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 15, 15, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 128)       147584    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 13, 13, 256)       33024     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 4, 4, 256)         65792     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 100)               51300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3797476 (14.49 MB)\n",
            "Trainable params: 3788516 (14.45 MB)\n",
            "Non-trainable params: 8960 (35.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "313/313 [==============================] - 16s 35ms/step - loss: 3.7146 - accuracy: 0.1499 - val_loss: 8.3078 - val_accuracy: 0.0185\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 2.9261 - accuracy: 0.2719 - val_loss: 4.9930 - val_accuracy: 0.1086\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 2.4478 - accuracy: 0.3626 - val_loss: 2.9803 - val_accuracy: 0.3041\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 2.1128 - accuracy: 0.4326 - val_loss: 2.7647 - val_accuracy: 0.3331\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 1.8306 - accuracy: 0.4977 - val_loss: 2.4802 - val_accuracy: 0.3958\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 1.5793 - accuracy: 0.5541 - val_loss: 2.7003 - val_accuracy: 0.3761\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 1.3376 - accuracy: 0.6128 - val_loss: 2.6730 - val_accuracy: 0.3929\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 1.1283 - accuracy: 0.6689 - val_loss: 2.6956 - val_accuracy: 0.4034\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.9320 - accuracy: 0.7212 - val_loss: 2.7678 - val_accuracy: 0.4059\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 10s 33ms/step - loss: 0.7572 - accuracy: 0.7674 - val_loss: 2.9440 - val_accuracy: 0.4036\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.9445 - accuracy: 0.4053\n",
            "Acurácia no conjunto de teste: 40.53%\n"
          ]
        }
      ],
      "source": [
        "# Treino e Teste\n",
        "model = get_cifar100_network()\n",
        "model.fit(train_images_cifar100, train_labels_cifar100, epochs=10, batch_size=128, validation_split=0.2)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images_cifar100, test_labels_cifar100)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOUrZZjVtkAg"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119Bmlh5451E",
        "outputId": "9843ee2b-fc3d-4b9c-9bcf-4115732ebf7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Carregar conjunto de dados\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sexhTEIstjHm"
      },
      "outputs": [],
      "source": [
        "def get_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7tmdkB4upn-",
        "outputId": "aadc3843-6ff0-49dc-f99f-041e7a9c78bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_99 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_105 (MaxPool  (None, 13, 13, 32)        0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " conv2d_100 (Conv2D)         (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_106 (MaxPool  (None, 5, 5, 64)          0         \n",
            " ing2D)                                                          \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 3, 3, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_210 (B  (None, 3, 3, 128)         512       \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " flatten_83 (Flatten)        (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 64)                73792     \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 167626 (654.79 KB)\n",
            "Trainable params: 167370 (653.79 KB)\n",
            "Non-trainable params: 256 (1.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 5ms/step - loss: 0.1444 - accuracy: 0.9581\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0768 - accuracy: 0.9799\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0624 - accuracy: 0.9841\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0574 - accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0516 - accuracy: 0.9875\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0469 - accuracy: 0.9884\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0431 - accuracy: 0.9898\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0413 - accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0392 - accuracy: 0.9911\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0361 - accuracy: 0.9918\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9928\n",
            "Acurácia no conjunto de teste: 99.28%\n"
          ]
        }
      ],
      "source": [
        "# Treino e Teste\n",
        "model = get_mnist_network()\n",
        "model.fit(train_images_mnist, train_labels_mnist, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images_mnist, test_labels_mnist)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkBlEy1ExHj"
      },
      "source": [
        "## Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O4u3Cqt35B6M"
      },
      "outputs": [],
      "source": [
        "# Carregar conjunto de dados\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images_fashion_mnist, train_labels_fashion_mnist), (test_images_fashion_mnist, test_labels_fashion_mnist) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN14IpXnFfCQ"
      },
      "outputs": [],
      "source": [
        "def get_fashion_mnist_network():\n",
        "    model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, kernel_size = 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size = 3, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPool2D(pool_size = 2),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(128, kernel_size = 5, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Conv2D(256, kernel_size = 5, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPm2TDGuu8WW",
        "outputId": "9eb034aa-8690-4c15-85e6-dc3583965183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_38 (Ba  (None, 26, 26, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 24, 24, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPooli  (None, 12, 12, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, 12, 12, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 8, 8, 128)         204928    \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_41 (Ba  (None, 8, 8, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 4, 4, 256)         819456    \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " batch_normalization_42 (Ba  (None, 4, 4, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 128)               524416    \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_43 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1579210 (6.02 MB)\n",
            "Trainable params: 1577866 (6.02 MB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 21s 9ms/step - loss: 0.4507 - accuracy: 0.8363\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.3028 - accuracy: 0.8907\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2588 - accuracy: 0.9063\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2331 - accuracy: 0.9151\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2115 - accuracy: 0.9232\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1949 - accuracy: 0.9283\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1789 - accuracy: 0.9341\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1644 - accuracy: 0.9392\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1523 - accuracy: 0.9447\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1430 - accuracy: 0.9479\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2046 - accuracy: 0.9311\n",
            "Acurácia no conjunto de teste: 93.11%\n"
          ]
        }
      ],
      "source": [
        "# Treino e Teste\n",
        "model = get_fashion_mnist_network()\n",
        "model.fit(train_images_fashion_mnist, train_labels_fashion_mnist, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images_fashion_mnist, test_labels_fashion_mnist)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iERVafMPF2Tn"
      },
      "source": [
        "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEUK1xk6Fk48"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": 101, \"acc\": 0.9928},\n",
        "    \"fashion_mnist\": {\"179\": None, \"acc\": 0.9311},\n",
        "    \"cifar10\": {\"time\": 161, \"acc\": 0.7384},\n",
        "    \"cifar100\": {\"time\": 106, \"acc\": 0.4053},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}